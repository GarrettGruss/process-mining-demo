{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 5: SHIP-Classified Process Mining on FSAE Telemetry\n",
    "\n",
    "This notebook implements the pipeline described in `overview.md`:\n",
    "\n",
    "```\n",
    "Raw Telemetry → SHIP Dispatcher → CaseGenerator → DFG / Variant Analysis\n",
    "```\n",
    "\n",
    "The SHIP Dispatcher reads a flat config list (`SHIP_EVENTS`) and classifies telemetry events\n",
    "into subsystems and SHIP transition types (`error_activation` / `error_recovery`).\n",
    "The CaseGenerator then builds time-windowed process mining cases around those events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport sys\nimport warnings\n\nimport pandas as pd\nimport pm4py\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, Image\n\nfrom examples.example_5.ship_config import SHIP_EVENTS\nfrom examples.example_5.ship_dispatcher import dispatch_ship_events\nfrom examples.example_4.case_generator import CaseGenerator\nfrom examples.example_4.variant_visualization import visualize_chevron_variants"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 190,587 rows × 76 columns\n",
      "Session: 2016-05-14 16:27:26.010000+00:00 → 2016-05-14 16:59:11.556000+00:00\n",
      "Duration: 1905.5 s\n"
     ]
    }
   ],
   "source": [
    "# Reuse the parsed telemetry from example_4 — no need to re-parse the raw AIM CSV.\n",
    "DATA_PATH = \"../example_4/data/processed/FSAE_Endurance_Full_parsed.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[\"time.absolute\"] = pd.to_datetime(df[\"time.absolute\"])\n",
    "\n",
    "print(f\"Loaded {len(df):,} rows x {df.shape[1]} columns\")\n",
    "print(f\"Session: {df['time.absolute'].min()} → {df['time.absolute'].max()}\")\n",
    "print(f\"Duration: {(df['time.absolute'].max() - df['time.absolute'].min()).total_seconds():.1f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Exploration for Threshold Calibration\n",
    "\n",
    "Review key channel statistics to confirm the thresholds in `ship_config.py` are data-appropriate.\n",
    "Adjust the config and re-run the dispatcher if distributions suggest different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_of_interest = {\n",
    "    \"Engine coolant temp (°F)\": \"f88.ect1_°f\",\n",
    "    \"Oil pressure (psi)\": \"f88.oil.p1_psi\",\n",
    "    \"Battery voltage (V)\": \"battery_v\",\n",
    "    \"GPS satellites\": \"gps.nsat_#\",\n",
    "    \"RPM\": \"f88.rpm_rpm\",\n",
    "    \"Throttle (%)\": \"f88.tps1_%\",\n",
    "    \"Vehicle speed (mph)\": \"f88.v.speed_mph\",\n",
    "    \"FL bumpstop (unit)\": \"fl.bumpstop_unit\",\n",
    "    \"Roll angle (unit)\": \"roll angle_unit\",\n",
    "}\n",
    "\n",
    "stats = pd.DataFrame(\n",
    "    {\n",
    "        label: df[col].describe(percentiles=[0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99])\n",
    "        for label, col in channels_of_interest.items()\n",
    "        if col in df.columns\n",
    "    }\n",
    ").T\n",
    "display(stats.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: SHIP Event Dispatch\n",
    "\n",
    "The dispatcher iterates over `SHIP_EVENTS`, calls the configured `EventClassifier` method,\n",
    "tags results with `subsystem` and `transition_type`, and concatenates into a single event log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings(record=True) as w:\n",
    "    warnings.simplefilter(\"always\")\n",
    "    event_log = dispatch_ship_events(df, SHIP_EVENTS)\n",
    "\n",
    "if w:\n",
    "    print(\"Dispatcher warnings:\")\n",
    "    for warning in w:\n",
    "        print(f\"  {warning.message}\")\n",
    "\n",
    "print(f\"\\nTotal SHIP events detected: {len(event_log):,}\")\n",
    "display(event_log.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event count by subsystem and transition type\n",
    "summary = (\n",
    "    event_log.groupby([\"subsystem\", \"transition_type\", \"activity\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values([\"subsystem\", \"transition_type\", \"count\"], ascending=[True, True, False])\n",
    ")\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Timeline: events over session time\nfig, ax = plt.subplots(figsize=(14, 4))\n\nsubsystems = event_log[\"subsystem\"].unique()\ncolors = plt.cm.tab10.colors\ncolor_map = {s: colors[i % len(colors)] for i, s in enumerate(sorted(subsystems))}\n\nfor subsystem, group in event_log.groupby(\"subsystem\"):\n    ax.scatter(\n        group[\"timestamp\"],\n        [subsystem] * len(group),\n        c=color_map[subsystem],\n        s=20,\n        alpha=0.6,\n        label=subsystem,\n    )\n\nax.set_xlabel(\"Session time\")\nax.set_title(\"SHIP events across the endurance session\")\nax.legend(loc=\"upper right\", fontsize=8)\nplt.tight_layout()\n\nos.makedirs(\"data/processed\", exist_ok=True)\nfig.savefig(\"data/processed/ship_events_timeline.png\", bbox_inches=\"tight\", dpi=150)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Case Generation\n",
    "\n",
    "Use `CaseGenerator` from example_4 to build time-windowed cases around `error_activation` events.\n",
    "Each case captures the 10 s before and 30 s after the triggering error, including any co-occurring\n",
    "events from other subsystems within that window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use error_activation events as case triggers\n",
    "activation_activities = (\n",
    "    event_log[event_log[\"transition_type\"] == \"error_activation\"][\"activity\"]\n",
    "    .unique()\n",
    "    .tolist()\n",
    ")\n",
    "print(f\"Trigger activities ({len(activation_activities)}):\")\n",
    "for a in sorted(activation_activities):\n",
    "    print(f\"  {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = CaseGenerator(event_log)\n",
    "cases = cg.generate_cases_time_window(\n",
    "    trigger_event=activation_activities,\n",
    "    time_before=10,\n",
    "    time_after=30,\n",
    "    case_prefix=\"SHIP\",\n",
    ")\n",
    "\n",
    "print(f\"\\nCases shape: {cases.shape}\")\n",
    "display(cases.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Distribution of events per case\nevents_per_case = cases.groupby(\"case_id\").size()\nfig, ax = plt.subplots(figsize=(8, 4))\nax.hist(events_per_case, bins=30, edgecolor=\"white\")\nax.set_xlabel(\"Events per case\")\nax.set_ylabel(\"Case count\")\nax.set_title(\"Distribution of events per SHIP case\")\nplt.tight_layout()\n\nfig.savefig(\"data/processed/ship_events_per_case.png\", bbox_inches=\"tight\", dpi=150)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: PM4Py Event Log Preparation\n",
    "\n",
    "Rename columns to the PM4Py standard and map `subsystem` → `org:resource`\n",
    "to enable SNA metrics in the stretch goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_df = cases.rename(\n",
    "    columns={\n",
    "        \"case_id\": \"case:concept:name\",\n",
    "        \"activity\": \"concept:name\",\n",
    "        \"timestamp\": \"time:timestamp\",\n",
    "        \"subsystem\": \"org:resource\",\n",
    "    }\n",
    ").copy()\n",
    "\n",
    "pm_df[\"time:timestamp\"] = pd.to_datetime(pm_df[\"time:timestamp\"])\n",
    "\n",
    "event_log_pm4py = pm4py.format_dataframe(\n",
    "    pm_df,\n",
    "    case_id=\"case:concept:name\",\n",
    "    activity_key=\"concept:name\",\n",
    "    timestamp_key=\"time:timestamp\",\n",
    ")\n",
    "\n",
    "print(f\"PM4Py event log: {len(event_log_pm4py):,} events across \"\n",
    "      f\"{event_log_pm4py['case:concept:name'].nunique()} cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: DFG Analysis\n",
    "\n",
    "Directly-Follows Graph (DFG) shows how SHIP events sequence across cases — which events\n",
    "tend to follow other events within the time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg, start_activities, end_activities = pm4py.discover_dfg(event_log_pm4py)\n",
    "\n",
    "print(f\"DFG: {len(dfg)} edges, {len(start_activities)} start activities, \"\n",
    "      f\"{len(end_activities)} end activities\")\n",
    "\n",
    "# Top 15 directly-follows edges\n",
    "top_edges = sorted(dfg.items(), key=lambda x: -x[1])[:15]\n",
    "print(\"\\nTop directly-follows edges:\")\n",
    "for (src, tgt), count in top_edges:\n",
    "    print(f\"  {count:4d}  {src}  →  {tgt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "os.makedirs(\"data/processed\", exist_ok=True)\n\npm4py.save_vis_dfg(\n    dfg,\n    start_activities,\n    end_activities,\n    file_path=\"data/processed/ship_dfg.png\",\n)\ndisplay(Image(\"data/processed/ship_dfg.png\"))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance DFG (mean time between events)\n",
    "pm4py.save_vis_performance_dfg(\n",
    "    *pm4py.discover_performance_dfg(event_log_pm4py),\n",
    "    file_path=\"data/processed/ship_dfg_performance.png\",\n",
    ")\n",
    "display(Image(\"data/processed/ship_dfg_performance.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Variant Analysis\n",
    "\n",
    "Identify unique event sequences (variants) across cases.  Each variant is a distinct\n",
    "ordering of SHIP events — variants that appear repeatedly represent recurring failure\n",
    "propagation patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = pm4py.get_variants(event_log_pm4py)\n",
    "\n",
    "print(f\"Total cases:    {event_log_pm4py['case:concept:name'].nunique()}\")\n",
    "print(f\"Unique variants: {len(variants)}\")\n",
    "print()\n",
    "\n",
    "# Sort by frequency\n",
    "sorted_variants = sorted(variants.items(), key=lambda x: -len(x[1]))\n",
    "\n",
    "print(\"Top 10 variants by case count:\")\n",
    "for i, (variant, case_set) in enumerate(sorted_variants[:10], 1):\n",
    "    seq = \" → \".join(variant)\n",
    "    print(f\"  [{len(case_set):3d} cases]  {seq[:120]}{'...' if len(seq) > 120 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chevron-style variant visualisation (reused from example_4)\n",
    "top_n = 12\n",
    "top_variants_seq = [list(v) for v, _ in sorted_variants[:top_n]]\n",
    "top_variants_counts = [len(cases_set) for _, cases_set in sorted_variants[:top_n]]\n",
    "\n",
    "fig = visualize_chevron_variants(\n",
    "    top_variants_seq,\n",
    "    top_variants_counts,\n",
    "    title=f\"Top {top_n} SHIP Event Variants\",\n",
    ")\n",
    "fig.savefig(\"data/processed/ship_variants.png\", bbox_inches=\"tight\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Subsystem-Filtered DFG\n",
    "\n",
    "Filter by transition type to answer targeted safety questions:\n",
    "- Which events precede `error_activation` events?\n",
    "- What is the typical recovery sequence after an error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFG for error_activation events only\n",
    "activation_log = event_log_pm4py[\n",
    "    event_log_pm4py[\"concept:name\"].isin(\n",
    "        event_log[event_log[\"transition_type\"] == \"error_activation\"][\"activity\"].unique()\n",
    "    )\n",
    "]\n",
    "\n",
    "if len(activation_log) > 0:\n",
    "    dfg_act, start_act, end_act = pm4py.discover_dfg(activation_log)\n",
    "    pm4py.save_vis_dfg(\n",
    "        dfg_act, start_act, end_act,\n",
    "        file_path=\"data/processed/ship_dfg_activations.png\",\n",
    "    )\n",
    "    print(f\"Activation-only DFG: {len(dfg_act)} edges\")\n",
    "    display(Image(\"data/processed/ship_dfg_activations.png\"))\n",
    "else:\n",
    "    print(\"No error_activation events in cases — adjust time window or thresholds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Stretch Goal — WaveletDenoiser\n",
    "\n",
    "The `WaveletDenoiser` class is implemented in `wavelet_denoiser.py`.  When `pywt` is\n",
    "installed (`pip install PyWavelets`), you can:\n",
    "\n",
    "1. Denoise noisy channels before feeding them to the dispatcher.\n",
    "2. Detect structural change points via energy thresholding (replacing ruptures).\n",
    "3. Register energy change events in `SHIP_EVENTS` with `method: \"detect_energy_change_points\"`.\n",
    "\n",
    "Example (un-comment and run after installing pywt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from examples.example_5.wavelet_denoiser import WaveletDenoiser\n",
    "#\n",
    "# wd = WaveletDenoiser(df, wavelet=\"db4\", level=4)\n",
    "#\n",
    "# # Denoise selected channels and rebuild the input DataFrame\n",
    "# noisy_channels = [\"f88.ect1_°f\", \"f88.oil.p1_psi\", \"battery_v\"]\n",
    "# denoised = wd.denoise_all(noisy_channels)\n",
    "# df_denoised = df.copy()\n",
    "# df_denoised[noisy_channels] = denoised\n",
    "#\n",
    "# # Add an energy-change entry to SHIP_EVENTS (stretch goal only)\n",
    "# SHIP_EVENTS_WITH_ENERGY = SHIP_EVENTS + [\n",
    "#     {\n",
    "#         \"subsystem\": \"Engine\",\n",
    "#         \"transition_type\": \"error_activation\",\n",
    "#         \"method\": \"detect_energy_change_points\",\n",
    "#         \"args\": {\n",
    "#             \"column\": \"f88.ect1_°f\",\n",
    "#             \"event_name\": \"engine_temp_energy_change\",\n",
    "#             \"threshold_sigma\": 3.0,\n",
    "#         },\n",
    "#     },\n",
    "# ]\n",
    "#\n",
    "# # Pass the WaveletDenoiser to the dispatcher — it routes energy-change calls to wd.\n",
    "# event_log_denoised = dispatch_ship_events(df_denoised, SHIP_EVENTS_WITH_ENERGY, wd=wd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "process-mining-demo (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}