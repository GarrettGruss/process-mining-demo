{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5673969",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This document covers the generation of an event driven analysis of an AIM-format FSAE log using process mining.\n",
    "\n",
    "## Code Overview\n",
    "\n",
    "1. Generate events from the log (Ex: Engine RPM high, wide open throttle, max corner).\n",
    "2. Select an event type of interest and draw a time boundary of +/- seconds around each event occurance.\n",
    "3. Group all events within each boundary by a common trace ID\n",
    "4. Perform the process mining\n",
    "5. Visualize the Performance DF and Markov DF\n",
    "\n",
    "## Use Cases\n",
    "- Turn events from a checklist run into DFG graphs.\n",
    "- Use case 1: (Fault Tree Analysis) Identify how failures cascade across a system (ex: from a minor fault to system failure)\n",
    "- Use case 2: (Event Tree Analysis) Identify which events are related to each other for system debugging or analysis\n",
    "- Use case 3: (Test and Verification) Identify if a system can meet a set of performance events, and identify what the deviations are and their behaviors.\n",
    "- Use Case 4: (Timing analysis) Model the time changes between events, and the 1 sigma deviations to visualize what went through the flow in nominal time, and what traces resulted in longer than nominal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d652991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages and setup environment\n",
    "import pandas as pd\n",
    "import pandera.pandas as pa\n",
    "\n",
    "filepath = \"./data/raw/FSAE_Endurance_Full.csv\"\n",
    "parsed_filepath = \"./data/processed/FSAE_Endurance_Full.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6133f025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time.lap_sec', 'distance_km', 'rr.shock_mm', 'rl.shock_mm', 'fl.shock_mm', 'fr.shock_mm', 'acc.lateral_g', 'acc.longitudin_g', 'rear.brake_psi', 'front.brake_psi', 'datalogger.tem_Â°f', 'battery_v', 'f88.rpm_rpm', 'f88.v.speed_mph', 'f88.d.speed_mph', 'f88.speed.fl_mph', 'f88.speed.fr_mph', 'f88.speed.rl_mph', 'f88.speed.rr_mph', 'f88.map1_mbar', 'f88.lambda1_a/f', 'f88.act1_Â°f', 'f88.ect1_Â°f', 'f88.gear_#', 'f88.oil.p1_psi', 'f88.v batt_v', 'f88.fuel.pr1_psi', 'f88.fuel.t_Â°f', 'f88.baro.pr_mbar', 'f88.tps1_%', 'f88.cal.switch_#', 'gps.speed_mph', 'gps.nsat_#', 'gps.latacc_g', 'gps.lonacc_g', 'gps.slope_deg', 'gps.heading_deg', 'gps.gyro_deg/s', 'gps.altitude_m', 'gps.posaccuracy_m', 'fl.shock.pos.zero_mm', 'fr.shock.pos.zero_mm', 'rl.shock.pos.zero_mm', 'rr.shock.pos.zero_mm', 'roll angle_unit', 'fr.roll.gradient_degree', 're.roll.gradient_degree', 'fl.shock.speed_mm/s', 'rr.shock.speed_mm/s', 'rl.shock.speed_mm/s', 'fr.shock.speed_mm/s', 'fl.bumpstop_unit', 'rr.bumpstop_unit', 'rl.bumpstop_unit', 'fr.bumpstop_unit', 'fl.shock.accel_mm/s/s', 'aim.time_s', 'cycle time_ms', 'injector duty_%', 'fuel flow_cc/min', 'fuel used_liters', 'aim.distancemeters_m', 'run.oil.pres_psi', 'run.oil.pres.hi_psi', 'load.oil.pres_psi', 'load.oil.pres.hi_psi', 'load.oil.pres.hi2_psi', 'force_unit', 'kw_unit', 'gps.latitude_Â°', 'gps.longitude_Â°', 'gps.elevation_cm', 'unnamed: 72_nan', 'lap', 'time.session_sec', 'time.absolute']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    parsed_filepath,\n",
    "    encoding=\"latin1\",\n",
    "    low_memory=False,  # Read entire file at once\n",
    ")\n",
    "\n",
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db7127",
   "metadata": {},
   "source": [
    "# Event conditions\n",
    "\n",
    "Based on the telemetry columns, here are relevant event conditions for an FSAE team:\n",
    "1. Lap Events (Fundamental)\n",
    "Lap Started: lap increments, time.lap_sec resets to ~0\n",
    "Lap Completed: time.lap_sec reaches max before reset\n",
    "Sector Crossing: Based on distance_km or aim.distancemeters_m thresholds\n",
    "2. Driver Performance Events\n",
    "Braking Events:\n",
    "Brake Applied: front.brake_psi or rear.brake_psi > threshold (e.g., 50 psi)\n",
    "Hard Braking: rear.brake_psi > 400 psi AND acc.longitudin_g < -1.0g\n",
    "Trail Braking: rear.brake_psi decreasing while acc.lateral_g > 0.5g\n",
    "Brake Released: front.brake_psi < threshold\n",
    "Cornering Events:\n",
    "High Lateral Load: acc.lateral_g > 1.2g (aggressive cornering)\n",
    "Corner Entry: acc.lateral_g increasing + speed decreasing\n",
    "Corner Apex: acc.lateral_g at local max + gps.gyro_deg/s at max\n",
    "Corner Exit: acc.lateral_g decreasing + f88.tps1_% increasing\n",
    "Throttle Events:\n",
    "Throttle Application: f88.tps1_% > 20%\n",
    "Full Throttle: f88.tps1_% > 90%\n",
    "Lift/Coast: f88.tps1_% < 10%\n",
    "Wheel Spin: f88.d.speed_mph significantly > gps.speed_mph\n",
    "3. Gear Shift Events\n",
    "Upshift: f88.gear_# increases\n",
    "Downshift: f88.gear_# decreases\n",
    "Shift Under Load: Gear change while f88.tps1_% > 50%\n",
    "Wrong Gear: f88.rpm_rpm outside optimal range for current gps.speed_mph\n",
    "4. Suspension/Chassis Events\n",
    "Bump/Compression:\n",
    "Bumpstop Hit: fl.bumpstop_unit, fr.bumpstop_unit, etc. = 1 (binary)\n",
    "Heavy Compression: Shock position (fl.shock_mm, etc.) > 80% travel\n",
    "Bottoming Event: Max compression rate + bumpstop contact\n",
    "Roll Event: roll angle_unit or fr.roll.gradient_degree > threshold\n",
    "Surface Conditions:\n",
    "Rough Surface: High variance in fl.shock.speed_mm/s or fl.shock.accel_mm/s/s\n",
    "Jump/Airborne: All shock sensors show rapid extension simultaneously\n",
    "5. Engine/Powertrain Events\n",
    "Performance:\n",
    "Launch: gps.speed_mph 0→moving + f88.tps1_% > 80%\n",
    "Rev Limiter Hit: f88.rpm_rpm at max sustained value\n",
    "Overrev: f88.rpm_rpm > safe threshold (e.g., 13,000 rpm)\n",
    "Lugging: f88.rpm_rpm < 3000 + high load\n",
    "Fuel System:\n",
    "Fuel Starvation: f88.lambda1_a/f goes lean (>15) + f88.fuel.pr1_psi drops\n",
    "Rich Condition: f88.lambda1_a/f < 12.5\n",
    "High Fuel Flow: fuel flow_cc/min at maximum\n",
    "6. Temperature Events\n",
    "Engine Overheating: f88.ect1_°f > 220°F\n",
    "Oil Overheating: f88.act1_°f > 280°F\n",
    "Cooling Recovery: Temperature decreasing after peak\n",
    "7. Pressure/Fluid Events\n",
    "Low Oil Pressure: f88.oil.p1_psi < 30 psi (critical)\n",
    "Oil Pressure Spike: run.oil.pres.hi_psi or load.oil.pres.hi_psi exceeds safe limit\n",
    "Low Fuel Pressure: f88.fuel.pr1_psi < threshold\n",
    "8. Electrical Events\n",
    "Low Battery Voltage: battery_v or f88.v batt_v < 12.0V\n",
    "Voltage Spike: battery_v > 15.0V\n",
    "GPS Lock Lost: gps.nsat_# < 4\n",
    "GPS Lock Acquired: gps.nsat_# >= 4\n",
    "9. Calibration/Mode Events\n",
    "Calibration Switch Change: f88.cal.switch_# changes value (e.g., rain mode, aggressive mode)\n",
    "Map Change: f88.map1_mbar threshold changes suggest different tuning\n",
    "10. Failure/Warning Events\n",
    "Wheel Lockup: Individual wheel speed (f88.speed.fl_mph, etc.) drops to 0 while others moving\n",
    "Loss of Traction: Rear wheel speeds >> front wheel speeds\n",
    "Sensor Anomaly: Any sensor reading NaN, out of physical bounds\n",
    "Data Logging Issue: cycle time_ms spikes (data acquisition lag)\n",
    "11. Track Position Events\n",
    "Straight Section: Low acc.lateral_g + high gps.speed_mph\n",
    "Technical Section: High frequency f88.gear_# changes\n",
    "Elevation Change: gps.slope_deg > threshold or gps.elevation_cm changing rapidly\n",
    "12. Comparative/Session Events\n",
    "Fastest Sector: Compare time.lap_sec at sector markers across laps\n",
    "Consistency Check: Lap time variance\n",
    "Setup Change: Between-run comparisons (different sessions in time.session_sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b484df42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EventExtractor class defined successfully\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Event Extraction from FSAE Telemetry Data\n",
    "\n",
    "This module extracts discrete events from continuous telemetry data based on\n",
    "threshold conditions and state changes.\n",
    "\n",
    "Considerations: Raw threshold-based methods on noisy telemetry can generate\n",
    "spurious events. Consider adding hysteresis (different thresholds for entering vs. exiting \n",
    "a state) or minimum dwell times to avoid event flooding. Threshold-based detection works \n",
    "well for known failure modes but struggles with gradual drift or context-dependent anomalies.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "\n",
    "class EventExtractor:\n",
    "    \"\"\"Extract events from FSAE telemetry dataframe based on defined conditions.\"\"\"\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        \"\"\"Initialize with telemetry dataframe.\n",
    "        \n",
    "        Args:\n",
    "            df: Telemetry dataframe with all sensor channels\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.events = []\n",
    "        \n",
    "    def detect_threshold_events(\n",
    "        self, \n",
    "        column: str, \n",
    "        threshold: float, \n",
    "        condition: str,\n",
    "        event_name: str,\n",
    "        min_duration_rows: int = 1\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Detect events where a column crosses a threshold.\n",
    "        \n",
    "        Args:\n",
    "            column: Column name to monitor\n",
    "            threshold: Threshold value\n",
    "            condition: Comparison operator ('>', '<', '>=', '<=', '==')\n",
    "            event_name: Name of the event\n",
    "            min_duration_rows: Minimum number of consecutive rows to confirm event\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with columns: timestamp, event_name, value, lap\n",
    "        \"\"\"\n",
    "        # Create boolean mask based on condition\n",
    "        if condition == '>':\n",
    "            mask = self.df[column] > threshold\n",
    "        elif condition == '<':\n",
    "            mask = self.df[column] < threshold\n",
    "        elif condition == '>=':\n",
    "            mask = self.df[column] >= threshold\n",
    "        elif condition == '<=':\n",
    "            mask = self.df[column] <= threshold\n",
    "        elif condition == '==':\n",
    "            mask = self.df[column] == threshold\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown condition: {condition}\")\n",
    "        \n",
    "        # Find rising edges (transitions from False to True)\n",
    "        rising_edge = mask & ~mask.shift(1).fillna(False)\n",
    "        \n",
    "        # Filter by minimum duration if specified\n",
    "        if min_duration_rows > 1:\n",
    "            # Check if condition stays true for min_duration_rows\n",
    "            duration_check = pd.Series(False, index=self.df.index)\n",
    "            for i in range(min_duration_rows):\n",
    "                duration_check |= mask.shift(-i).fillna(False)\n",
    "            rising_edge = rising_edge & duration_check\n",
    "        \n",
    "        # Extract events\n",
    "        event_indices = self.df[rising_edge].index\n",
    "        events_df = pd.DataFrame({\n",
    "            'timestamp': self.df.loc[event_indices, 'time.absolute'],\n",
    "            'activity': event_name,\n",
    "            'value': self.df.loc[event_indices, column],\n",
    "            'lap': self.df.loc[event_indices, 'lap'],\n",
    "            'session_time': self.df.loc[event_indices, 'time.session_sec']\n",
    "        })\n",
    "        \n",
    "        return events_df.reset_index(drop=True)\n",
    "    \n",
    "    def detect_state_change_events(\n",
    "        self,\n",
    "        column: str,\n",
    "        event_name_prefix: str,\n",
    "        ignore_nan: bool = True\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Detect when a column value changes (e.g., gear shifts, calibration changes).\n",
    "        \n",
    "        Args:\n",
    "            column: Column name to monitor\n",
    "            event_name_prefix: Prefix for event name (will append old->new values)\n",
    "            ignore_nan: Whether to ignore NaN values\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with event details\n",
    "        \"\"\"\n",
    "        # Find where values change\n",
    "        if ignore_nan:\n",
    "            value_changed = (self.df[column] != self.df[column].shift(1)) & \\\n",
    "                           self.df[column].notna() & \\\n",
    "                           self.df[column].shift(1).notna()\n",
    "        else:\n",
    "            value_changed = self.df[column] != self.df[column].shift(1)\n",
    "        \n",
    "        event_indices = self.df[value_changed].index\n",
    "        \n",
    "        events_df = pd.DataFrame({\n",
    "            'timestamp': self.df.loc[event_indices, 'time.absolute'],\n",
    "            'activity': [\n",
    "                f\"{event_name_prefix} {self.df.loc[idx-1, column]:.0f}->{self.df.loc[idx, column]:.0f}\"\n",
    "                if idx > self.df.index[0] else f\"{event_name_prefix} Start\"\n",
    "                for idx in event_indices\n",
    "            ],\n",
    "            'value': self.df.loc[event_indices, column],\n",
    "            'lap': self.df.loc[event_indices, 'lap'],\n",
    "            'session_time': self.df.loc[event_indices, 'time.session_sec']\n",
    "        })\n",
    "        \n",
    "        return events_df.reset_index(drop=True)\n",
    "    \n",
    "    def detect_combined_condition_events(\n",
    "        self,\n",
    "        conditions: List[Tuple[str, str, float]],\n",
    "        event_name: str,\n",
    "        mode: str = 'all'\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Detect events based on multiple conditions.\n",
    "        \n",
    "        Args:\n",
    "            conditions: List of (column, operator, threshold) tuples\n",
    "            event_name: Name of the event\n",
    "            mode: 'all' (AND) or 'any' (OR) for combining conditions\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with event details\n",
    "        \"\"\"\n",
    "        masks = []\n",
    "        for column, operator, threshold in conditions:\n",
    "            if operator == '>':\n",
    "                masks.append(self.df[column] > threshold)\n",
    "            elif operator == '<':\n",
    "                masks.append(self.df[column] < threshold)\n",
    "            elif operator == '>=':\n",
    "                masks.append(self.df[column] >= threshold)\n",
    "            elif operator == '<=':\n",
    "                masks.append(self.df[column] <= threshold)\n",
    "            elif operator == '==':\n",
    "                masks.append(self.df[column] == threshold)\n",
    "        \n",
    "        # Combine masks\n",
    "        if mode == 'all':\n",
    "            combined_mask = pd.Series(True, index=self.df.index)\n",
    "            for mask in masks:\n",
    "                combined_mask &= mask\n",
    "        else:  # 'any'\n",
    "            combined_mask = pd.Series(False, index=self.df.index)\n",
    "            for mask in masks:\n",
    "                combined_mask |= mask\n",
    "        \n",
    "        # Find rising edges\n",
    "        rising_edge = combined_mask & ~combined_mask.shift(1).fillna(False)\n",
    "        event_indices = self.df[rising_edge].index\n",
    "        \n",
    "        events_df = pd.DataFrame({\n",
    "            'timestamp': self.df.loc[event_indices, 'time.absolute'],\n",
    "            'activity': event_name,\n",
    "            'value': None,\n",
    "            'lap': self.df.loc[event_indices, 'lap'],\n",
    "            'session_time': self.df.loc[event_indices, 'time.session_sec']\n",
    "        })\n",
    "        \n",
    "        return events_df.reset_index(drop=True)\n",
    "    \n",
    "    def detect_local_extrema_events(\n",
    "        self,\n",
    "        column: str,\n",
    "        event_name_max: str,\n",
    "        event_name_min: str,\n",
    "        window_size: int = 10,\n",
    "        prominence: float = 0.1\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Detect local maxima and minima (e.g., corner apex).\n",
    "        \n",
    "        Args:\n",
    "            column: Column to analyze\n",
    "            event_name_max: Name for maximum events\n",
    "            event_name_min: Name for minimum events\n",
    "            window_size: Size of window for local comparison\n",
    "            prominence: Minimum prominence (difference from neighbors)\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with event details\n",
    "        \"\"\"\n",
    "        from scipy.signal import find_peaks\n",
    "        \n",
    "        values = self.df[column].fillna(0).values\n",
    "        \n",
    "        # Find peaks (maxima)\n",
    "        peaks_max, _ = find_peaks(values, distance=window_size, prominence=prominence)\n",
    "        # Find valleys (minima)\n",
    "        peaks_min, _ = find_peaks(-values, distance=window_size, prominence=prominence)\n",
    "        \n",
    "        # Create events for maxima\n",
    "        events_max = pd.DataFrame({\n",
    "            'timestamp': self.df.iloc[peaks_max]['time.absolute'].values,\n",
    "            'activity': event_name_max,\n",
    "            'value': self.df.iloc[peaks_max][column].values,\n",
    "            'lap': self.df.iloc[peaks_max]['lap'].values,\n",
    "            'session_time': self.df.iloc[peaks_max]['time.session_sec'].values\n",
    "        })\n",
    "        \n",
    "        # Create events for minima\n",
    "        events_min = pd.DataFrame({\n",
    "            'timestamp': self.df.iloc[peaks_min]['time.absolute'].values,\n",
    "            'activity': event_name_min,\n",
    "            'value': self.df.iloc[peaks_min][column].values,\n",
    "            'lap': self.df.iloc[peaks_min]['lap'].values,\n",
    "            'session_time': self.df.iloc[peaks_min]['time.session_sec'].values\n",
    "        })\n",
    "        \n",
    "        return pd.concat([events_max, events_min], ignore_index=True).sort_values('timestamp')\n",
    "    \n",
    "\n",
    "print(\"EventExtractor class defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1wijdk35t7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event extractor initialized with 190587 telemetry rows\n",
      "Time range: 0.01s to 1905.56s\n",
      "Number of laps: 22\n"
     ]
    }
   ],
   "source": [
    "# Initialize the event extractor\n",
    "extractor = EventExtractor(df)\n",
    "\n",
    "print(f\"Event extractor initialized with {len(df)} telemetry rows\")\n",
    "print(f\"Time range: {df['time.session_sec'].min():.2f}s to {df['time.session_sec'].max():.2f}s\")\n",
    "print(f\"Number of laps: {df['lap'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inrnxk4e7m",
   "metadata": {},
   "source": [
    "# Extract Events\n",
    "\n",
    "Now we'll extract various types of events from the telemetry data using the EventExtractor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6mfw506z0vx",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting lap events...\n",
      "  Found 21 lap transitions\n",
      "Extracting gear shift events...\n",
      "  Found 1702 gear shifts\n",
      "Extracting braking events...\n",
      "  Found 373 brake applications\n",
      "  Found 0 hard braking events\n",
      "Extracting throttle events...\n",
      "  Found 63 full throttle events\n",
      "Extracting cornering events...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_421671/3459389395.py:65: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rising_edge = mask & ~mask.shift(1).fillna(False)\n",
      "/tmp/ipykernel_421671/3459389395.py:72: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  duration_check |= mask.shift(-i).fillna(False)\n",
      "/tmp/ipykernel_421671/3459389395.py:167: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rising_edge = combined_mask & ~combined_mask.shift(1).fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 4122 corner apex events\n",
      "Extracting high lateral load events...\n",
      "  Found 1377 high lateral load events\n",
      "Extracting suspension bumpstop events...\n",
      "  Found 19 bumpstop hits on FL\n",
      "  Found 19 bumpstop hits on FR\n",
      "  Found 19 bumpstop hits on RL\n",
      "  Found 19 bumpstop hits on RR\n",
      "Extracting engine events...\n",
      "  Found 4 high RPM events\n",
      "Extracting oil pressure events...\n",
      "  Found 461 low oil pressure warnings\n",
      "Extracting GPS events...\n",
      "\n",
      "============================================================\n",
      "Total event categories: 13\n",
      "Total events extracted: 8199\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Extract all event types from telemetry data.\"\"\"\n",
    "\n",
    "all_events = []\n",
    "\n",
    "# 1. LAP EVENTS\n",
    "print(\"Extracting lap events...\")\n",
    "lap_events = extractor.detect_state_change_events(\n",
    "    column='lap',\n",
    "    event_name_prefix='Lap'\n",
    ")\n",
    "all_events.append(lap_events)\n",
    "print(f\"  Found {len(lap_events)} lap transitions\")\n",
    "\n",
    "# 2. GEAR SHIFT EVENTS\n",
    "print(\"Extracting gear shift events...\")\n",
    "gear_events = extractor.detect_state_change_events(\n",
    "    column='f88.gear_#',\n",
    "    event_name_prefix='Gear Shift'\n",
    ")\n",
    "all_events.append(gear_events)\n",
    "print(f\"  Found {len(gear_events)} gear shifts\")\n",
    "\n",
    "# 3. BRAKING EVENTS\n",
    "print(\"Extracting braking events...\")\n",
    "brake_applied = extractor.detect_threshold_events(\n",
    "    column='front.brake_psi',\n",
    "    threshold=50,\n",
    "    condition='>',\n",
    "    event_name='Brake Applied',\n",
    "    min_duration_rows=3\n",
    ")\n",
    "all_events.append(brake_applied)\n",
    "print(f\"  Found {len(brake_applied)} brake applications\")\n",
    "\n",
    "hard_braking = extractor.detect_combined_condition_events(\n",
    "    conditions=[\n",
    "        ('rear.brake_psi', '>', 400),\n",
    "        ('acc.longitudin_g', '<', -1.0)\n",
    "    ],\n",
    "    event_name='Hard Braking',\n",
    "    mode='all'\n",
    ")\n",
    "all_events.append(hard_braking)\n",
    "print(f\"  Found {len(hard_braking)} hard braking events\")\n",
    "\n",
    "# 4. THROTTLE EVENTS\n",
    "print(\"Extracting throttle events...\")\n",
    "full_throttle = extractor.detect_threshold_events(\n",
    "    column='f88.tps1_%',\n",
    "    threshold=90,\n",
    "    condition='>',\n",
    "    event_name='Full Throttle',\n",
    "    min_duration_rows=5\n",
    ")\n",
    "all_events.append(full_throttle)\n",
    "print(f\"  Found {len(full_throttle)} full throttle events\")\n",
    "\n",
    "# 5. CORNERING EVENTS - Local maxima in lateral acceleration\n",
    "print(\"Extracting cornering events...\")\n",
    "corner_events = extractor.detect_local_extrema_events(\n",
    "    column='acc.lateral_g',\n",
    "    event_name_max='Corner Apex (Left)',\n",
    "    event_name_min='Corner Apex (Right)',\n",
    "    window_size=20,\n",
    "    prominence=0.3\n",
    ")\n",
    "all_events.append(corner_events)\n",
    "print(f\"  Found {len(corner_events)} corner apex events\")\n",
    "\n",
    "# 6. HIGH LATERAL LOAD EVENTS\n",
    "print(\"Extracting high lateral load events...\")\n",
    "high_lateral = extractor.detect_threshold_events(\n",
    "    column='acc.lateral_g',\n",
    "    threshold=1.2,\n",
    "    condition='>',\n",
    "    event_name='High Lateral Load',\n",
    "    min_duration_rows=5\n",
    ")\n",
    "all_events.append(high_lateral)\n",
    "print(f\"  Found {len(high_lateral)} high lateral load events\")\n",
    "\n",
    "# 7. BUMPSTOP EVENTS\n",
    "print(\"Extracting suspension bumpstop events...\")\n",
    "for corner in ['fl', 'fr', 'rl', 'rr']:\n",
    "    bumpstop = extractor.detect_threshold_events(\n",
    "        column=f'{corner}.bumpstop_unit',\n",
    "        threshold=0.5,\n",
    "        condition='>',\n",
    "        event_name=f'Bumpstop Hit ({corner.upper()})',\n",
    "        min_duration_rows=1\n",
    "    )\n",
    "    if len(bumpstop) > 0:\n",
    "        all_events.append(bumpstop)\n",
    "        print(f\"  Found {len(bumpstop)} bumpstop hits on {corner.upper()}\")\n",
    "\n",
    "# 8. ENGINE EVENTS\n",
    "print(\"Extracting engine events...\")\n",
    "high_rpm = extractor.detect_threshold_events(\n",
    "    column='f88.rpm_rpm',\n",
    "    threshold=11000,\n",
    "    condition='>',\n",
    "    event_name='High RPM',\n",
    "    min_duration_rows=10\n",
    ")\n",
    "all_events.append(high_rpm)\n",
    "print(f\"  Found {len(high_rpm)} high RPM events\")\n",
    "\n",
    "# 9. LOW OIL PRESSURE WARNING\n",
    "print(\"Extracting oil pressure events...\")\n",
    "low_oil_pressure = extractor.detect_threshold_events(\n",
    "    column='f88.oil.p1_psi',\n",
    "    threshold=30,\n",
    "    condition='<',\n",
    "    event_name='Low Oil Pressure Warning',\n",
    "    min_duration_rows=5\n",
    ")\n",
    "if len(low_oil_pressure) > 0:\n",
    "    all_events.append(low_oil_pressure)\n",
    "    print(f\"  Found {len(low_oil_pressure)} low oil pressure warnings\")\n",
    "\n",
    "# 10. GPS EVENTS\n",
    "print(\"Extracting GPS events...\")\n",
    "gps_lock_lost = extractor.detect_threshold_events(\n",
    "    column='gps.nsat_#',\n",
    "    threshold=4,\n",
    "    condition='<',\n",
    "    event_name='GPS Lock Lost',\n",
    "    min_duration_rows=10\n",
    ")\n",
    "if len(gps_lock_lost) > 0:\n",
    "    all_events.append(gps_lock_lost)\n",
    "    print(f\"  Found {len(gps_lock_lost)} GPS lock lost events\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Total event categories: {len(all_events)}\")\n",
    "print(f\"Total events extracted: {sum(len(e) for e in all_events)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grcgmapwwsv",
   "metadata": {},
   "source": [
    "# Combine Events into Event Log\n",
    "\n",
    "Merge all extracted events into a single event dataframe suitable for process mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ju7c054sk3h",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Event Log Statistics:\n",
      "============================================================\n",
      "Total events: 8199\n",
      "Unique activities: 52\n",
      "Unique cases (laps): 22\n",
      "Time span: 2016-05-14T16:27:26.010000Z to 2016-05-14T16:59:09.000000Z\n",
      "\n",
      "Event distribution by activity type:\n",
      "activity\n",
      "Corner Apex (Right)         2070\n",
      "Corner Apex (Left)          2052\n",
      "High Lateral Load           1377\n",
      "Low Oil Pressure Warning     461\n",
      "Brake Applied                373\n",
      "Gear Shift 3->3              322\n",
      "Gear Shift 4->4              284\n",
      "Gear Shift 2->2              178\n",
      "Gear Shift 5->5              163\n",
      "Gear Shift 4->3              112\n",
      "Gear Shift 3->4              112\n",
      "Gear Shift 4->5               86\n",
      "Gear Shift 5->4               84\n",
      "Gear Shift 3->2               76\n",
      "Gear Shift 2->3               76\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 10 events:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_421671/108663020.py:2: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  events_df = pd.concat(all_events, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>case_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activity</th>\n",
       "      <th>lap</th>\n",
       "      <th>session_time</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Lap_1</td>\n",
       "      <td>2016-05-14T16:27:26.010000Z</td>\n",
       "      <td>Bumpstop Hit (FL)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Lap_1</td>\n",
       "      <td>2016-05-14T16:27:26.010000Z</td>\n",
       "      <td>Bumpstop Hit (RL)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Lap_1</td>\n",
       "      <td>2016-05-14T16:27:26.010000Z</td>\n",
       "      <td>Bumpstop Hit (RR)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Lap_1</td>\n",
       "      <td>2016-05-14T16:27:26.010000Z</td>\n",
       "      <td>Low Oil Pressure Warning</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Lap_1</td>\n",
       "      <td>2016-05-14T16:27:26.010000Z</td>\n",
       "      <td>Bumpstop Hit (FR)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Lap_1</td>\n",
       "      <td>2016-05-14T16:27:27.930000Z</td>\n",
       "      <td>Bumpstop Hit (FR)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Lap_1</td>\n",
       "      <td>2016-05-14T16:27:27.930000Z</td>\n",
       "      <td>Bumpstop Hit (RL)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Lap_1</td>\n",
       "      <td>2016-05-14T16:27:27.930000Z</td>\n",
       "      <td>Bumpstop Hit (FL)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Lap_1</td>\n",
       "      <td>2016-05-14T16:27:27.930000Z</td>\n",
       "      <td>Bumpstop Hit (RR)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Lap_1</td>\n",
       "      <td>2016-05-14T16:27:44.090000Z</td>\n",
       "      <td>Gear Shift 0-&gt;0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.09</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id case_id                    timestamp                  activity  \\\n",
       "0         1   Lap_1  2016-05-14T16:27:26.010000Z         Bumpstop Hit (FL)   \n",
       "1         2   Lap_1  2016-05-14T16:27:26.010000Z         Bumpstop Hit (RL)   \n",
       "2         3   Lap_1  2016-05-14T16:27:26.010000Z         Bumpstop Hit (RR)   \n",
       "3         4   Lap_1  2016-05-14T16:27:26.010000Z  Low Oil Pressure Warning   \n",
       "4         5   Lap_1  2016-05-14T16:27:26.010000Z         Bumpstop Hit (FR)   \n",
       "5         6   Lap_1  2016-05-14T16:27:27.930000Z         Bumpstop Hit (FR)   \n",
       "6         7   Lap_1  2016-05-14T16:27:27.930000Z         Bumpstop Hit (RL)   \n",
       "7         8   Lap_1  2016-05-14T16:27:27.930000Z         Bumpstop Hit (FL)   \n",
       "8         9   Lap_1  2016-05-14T16:27:27.930000Z         Bumpstop Hit (RR)   \n",
       "9        10   Lap_1  2016-05-14T16:27:44.090000Z           Gear Shift 0->0   \n",
       "\n",
       "   lap  session_time  value  \n",
       "0    1          0.01    5.0  \n",
       "1    1          0.01    5.0  \n",
       "2    1          0.01    5.0  \n",
       "3    1          0.01    0.0  \n",
       "4    1          0.01    5.0  \n",
       "5    1          1.93    2.0  \n",
       "6    1          1.93    2.0  \n",
       "7    1          1.93    2.0  \n",
       "8    1          1.93    2.0  \n",
       "9    1         18.09    0.4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all events into a single dataframe\n",
    "events_df = pd.concat(all_events, ignore_index=True)\n",
    "\n",
    "# Sort by timestamp\n",
    "events_df = events_df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "# Add an event_id column\n",
    "events_df.insert(0, 'event_id', range(1, len(events_df) + 1))\n",
    "\n",
    "# Add case_id (use lap number as case identifier)\n",
    "events_df['case_id'] = 'Lap_' + events_df['lap'].astype(int).astype(str)\n",
    "\n",
    "# Reorder columns for clarity\n",
    "events_df = events_df[['event_id', 'case_id', 'timestamp', 'activity', 'lap', 'session_time', 'value']]\n",
    "\n",
    "event_log_path = \"./data/processed/FSAE_Event_Log.csv\"\n",
    "events_df.to_csv(event_log_path, index=False)\n",
    "\n",
    "print(f\"Combined Event Log Statistics:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total events: {len(events_df)}\")\n",
    "print(f\"Unique activities: {events_df['activity'].nunique()}\")\n",
    "print(f\"Unique cases (laps): {events_df['case_id'].nunique()}\")\n",
    "print(f\"Time span: {events_df['timestamp'].min()} to {events_df['timestamp'].max()}\")\n",
    "print(f\"\\nEvent distribution by activity type:\")\n",
    "print(events_df['activity'].value_counts().head(15))\n",
    "print(f\"\\nFirst 10 events:\")\n",
    "events_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "process-mining-demo (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
